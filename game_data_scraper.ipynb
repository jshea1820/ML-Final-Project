{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"export PATH=$PATH:$(pwd)\")\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options,\n",
    "    \n",
    "    # Change this to the local absolute path to project directory\n",
    "    executable_path='/Users/jshea/Desktop/school/spring_2020/machine_learning/ML-Final-Project/chromedriver'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_urls(season):\n",
    "    ''' Get premier league team urls for a given season '''\n",
    "    \n",
    "    # List to record all the team page urls for this season (starts with Man City)\n",
    "    team_urls = [\"https://fbref.com/en/squads/b8fd03ef/{}/Manchester-City\".format(season)]\n",
    "    url = team_urls[0]\n",
    "\n",
    "    # Loads page and gets matchup records for Man City in the current season\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    matchup_records = soup.body.find_all(\n",
    "        \"div\", {\"id\": \"all_kitchen_sink_sched\"})[0].find(\"div\").find(\"div\").find_all(\n",
    "            \"div\", {\"class\", \"table_outer_container mobile_table\"})[0].find_all(\n",
    "                \"div\", {\"class\", \"overthrow table_container\"})[0].find_all(\n",
    "                    \"tbody\")[0].find_all(\"tr\")\n",
    "\n",
    "    # Loops through records and extracts links to opponent pages\n",
    "    for record in matchup_records:\n",
    "\n",
    "        # Makes sure matchup is premier league\n",
    "        try:\n",
    "            league = record.th.a.text\n",
    "        except:\n",
    "            continue\n",
    "        if league == \"Premier League\":\n",
    "\n",
    "            # Gets opponent page url\n",
    "            opponent_link = record.find(\"td\", {\"data-stat\": \"opponent\"}).a[\"href\"]\n",
    "            team_code = opponent_link.split(\"/\")[3]\n",
    "            team_name = opponent_link.split(\"/\")[5]\n",
    "            team_urls.append(\"https://fbref.com/en/squads/{}/{}/{}\".format(team_code, season, team_name))\n",
    "\n",
    "    # Dudups team urls\n",
    "    team_urls = list(set(team_urls))\n",
    "    \n",
    "    return team_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matchup_urls(team_url):\n",
    "    ''' Get all the matchup urls corresponding to a team url '''\n",
    "\n",
    "    # Loads page and gets matchup records\n",
    "    driver.get(team_url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    matchup_records = soup.body.find_all(\n",
    "        \"div\", {\"id\": \"all_kitchen_sink_sched\"})[0].find(\"div\").find(\"div\").find_all(\n",
    "            \"div\", {\"class\", \"table_outer_container mobile_table\"})[0].find_all(\n",
    "                \"div\", {\"class\", \"overthrow table_container\"})[0].find_all(\n",
    "                    \"tbody\")[0].find_all(\"tr\")\n",
    "\n",
    "    # Loops through records and extracts opponent links\n",
    "    matchup_urls = []\n",
    "    for record in matchup_records:\n",
    "\n",
    "        # Makes sure matchup is premier league\n",
    "        try:\n",
    "            league = record.th.a.text\n",
    "        except:\n",
    "            continue\n",
    "        if league == \"Premier League\":\n",
    "\n",
    "            match_link = record.find(\"td\", {\"data-stat\": \"match_report\"}).a[\"href\"]\n",
    "            match_code = match_link.split(\"/\")[3]\n",
    "            match_title = match_link.split(\"/\")[4]\n",
    "            matchup_urls.append(\"https://fbref.com/en/matches/{}/{}\".format(match_code, match_title))\n",
    "\n",
    "    return matchup_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets urls to all matchups in given seasons\n",
    "\n",
    "all_matchups = []\n",
    "\n",
    "# Loops through season\n",
    "for season in [\"2018-2019\"]:\n",
    "    \n",
    "    # Gets all 20 team urls for the season\n",
    "    team_urls = get_team_urls(season)\n",
    "    \n",
    "    # For each team, get all their matchup urls\n",
    "    for team_url in team_urls:\n",
    "        print(\"Getting matches for url {}\".format(team_url))\n",
    "        \n",
    "        all_matchups = all_matchups + get_matchup_urls(team_url)\n",
    "        \n",
    "    # Dedup matchup urls\n",
    "    all_matchups = list(set(all_matchups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracted {} matchup urls\".format(len(all_matchups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(match_url):\n",
    "    ''' gets all associated match data from a given match page '''\n",
    "    \n",
    "    # Loads page\n",
    "    driver.get(match_url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Dict to store all match associated data\n",
    "    match_dict = {\"url\": match_url}\n",
    "    \n",
    "    match_dict[\"date\"] = soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox_meta\"})[0].find_all(\"strong\")[0].a.text\n",
    "\n",
    "    match_dict[\"week\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"content\"})[0].div.text[26:-1])\n",
    "    \n",
    "    match_dict[\"home_team\"] = soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"strong\")[0].a[\"href\"].split(\"/\")[5]\n",
    "    match_dict[\"away_team\"] = soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"strong\")[3].a[\"href\"].split(\"/\")[5]\n",
    "    \n",
    "    match_dict[\"home_record\"] = soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\")[6].text\n",
    "    match_dict[\"away_record\"] = soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\")[16].text\n",
    "    \n",
    "    match_dict[\"home_score\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\", {\"class\": \"score\"})[0].text)\n",
    "    match_dict[\"away_score\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\", {\"class\": \"score\"})[1].text)\n",
    "    \n",
    "    match_dict[\"home_score_xg\"] = float(soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\", {\"class\": \"score_xg\"})[0].text)\n",
    "    match_dict[\"away_score_xg\"] = float(soup.body.find_all(\n",
    "        \"div\", {\"class\": \"scorebox\"})[0].find_all(\"div\", {\"class\": \"score_xg\"})[1].text)\n",
    "    \n",
    "    try:\n",
    "        match_dict[\"home_possession\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[0].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"home_possession\"] = 0\n",
    "    try:\n",
    "        match_dict[\"away_possession\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[1].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"away_possession\"] = 0\n",
    "    \n",
    "    try:\n",
    "        match_dict[\"home_pass_acc\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[2].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"home_pass_acc\"] = 0\n",
    "    try:\n",
    "        match_dict[\"away_pass_acc\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[3].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"away_pass_acc\"] = 0\n",
    "    \n",
    "    try:\n",
    "        match_dict[\"home_sot\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[4].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"home_sot\"] = 0\n",
    "    try:\n",
    "        match_dict[\"away_sot\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[5].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"away_sot\"] = 0\n",
    "    \n",
    "    try:\n",
    "        match_dict[\"home_saves\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[6].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"home_saves\"] = 0\n",
    "    try:\n",
    "        match_dict[\"away_saves\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats\"})[0].find_all(\"strong\")[7].text[:-1])\n",
    "    except:\n",
    "        match_dict[\"away_saves\"] = 0\n",
    "    \n",
    "    match_dict[\"home_fouls\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[4].text)\n",
    "    match_dict[\"away_fouls\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[6].text)\n",
    "    \n",
    "    match_dict[\"home_corners\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[7].text)\n",
    "    match_dict[\"away_corners\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[9].text)\n",
    "    \n",
    "    match_dict[\"home_crosses\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[10].text)\n",
    "    match_dict[\"away_crosses\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[12].text)\n",
    "    \n",
    "    match_dict[\"home_touches\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[13].text)\n",
    "    match_dict[\"away_touches\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[15].text)\n",
    "    \n",
    "    match_dict[\"home_tackles\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[20].text)\n",
    "    match_dict[\"away_tackles\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[22].text)\n",
    "    \n",
    "    match_dict[\"home_ints\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[23].text)\n",
    "    match_dict[\"away_ints\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[25].text)\n",
    "    \n",
    "    match_dict[\"home_aerials\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[26].text)\n",
    "    match_dict[\"away_aerials\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[28].text)\n",
    "    \n",
    "    match_dict[\"home_clearances\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[29].text)\n",
    "    match_dict[\"away_clearances\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[31].text)\n",
    "    \n",
    "    match_dict[\"home_offsides\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[36].text)\n",
    "    match_dict[\"away_offsides\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[38].text)\n",
    "    \n",
    "    match_dict[\"home_goal_kicks\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[39].text)\n",
    "    match_dict[\"away_goal_kicks\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[41].text)\n",
    "    \n",
    "    match_dict[\"home_throwins\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[42].text)\n",
    "    match_dict[\"away_throwins\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[44].text)\n",
    "    \n",
    "    match_dict[\"home_longballs\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[45].text)\n",
    "    match_dict[\"away_longballs\"] = int(soup.body.find_all(\n",
    "        \"div\", {\"id\": \"team_stats_extra\"})[0].find_all(\"div\")[47].text)\n",
    "    \n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "df = {}\n",
    "for m_url in all_matchups:\n",
    "    print(m_url)\n",
    "    \n",
    "    # Get the match data\n",
    "    d = get_match_data(m_url)\n",
    "    \n",
    "    # For first value, set up the dict keys\n",
    "    if i == 0:\n",
    "        for key in d.keys():\n",
    "            df[key] = []\n",
    "            \n",
    "    # Append values to df dict\n",
    "    for key in d.keys():\n",
    "        df[key].append(d[key])\n",
    "            \n",
    "    i += 1\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prime = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prime.to_csv(\"matchup_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://fbref.com/en/matches/806cb036/Manchester-United-Brighton--Hove-Albion-January-19-2019-Premier-League\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
